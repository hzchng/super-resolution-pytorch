{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from src import checkpoint, data, metrics\n",
    "from src.device import device\n",
    "from src.model import Discriminator, Generator\n",
    "from src.utils import UtilSRGAN\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.SRGANData(\n",
    "    root_dir=Path(\"data/train\"),\n",
    "    scale=UtilSRGAN.scale,\n",
    "    hr_name=\"hr\",\n",
    "    # lr_name=\"low_bicubic_x2\",\n",
    "    init_transfrom=UtilSRGAN.init_transform,\n",
    "    hr_transform=UtilSRGAN.hr_transforms,\n",
    "    lr_transform=UtilSRGAN.lr_transforms,\n",
    ")\n",
    "\n",
    "eval_data_set5 = data.SRGANData(\n",
    "    root_dir=Path(\"data/test\"),\n",
    "    scale=UtilSRGAN.scale,\n",
    "    hr_name=\"Set5\",\n",
    "    init_transfrom=UtilSRGAN.init_eval_transform,\n",
    "    hr_transform=UtilSRGAN.hr_transforms,\n",
    "    lr_transform=UtilSRGAN.lr_transforms,\n",
    ")\n",
    "\n",
    "eval_data_set14 = data.SRGANData(\n",
    "    root_dir=Path(\"data/test\"),\n",
    "    scale=UtilSRGAN.scale,\n",
    "    hr_name=\"Set14\",\n",
    "    init_transfrom=UtilSRGAN.init_eval_transform,\n",
    "    hr_transform=UtilSRGAN.hr_transforms,\n",
    "    lr_transform=UtilSRGAN.lr_transforms,\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=False, num_workers=4)\n",
    "eval_loader_set5 = DataLoader(eval_data_set5, batch_size=1, shuffle=False, num_workers=1)\n",
    "eval_loader_set14 = DataLoader(eval_data_set14, batch_size=1, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(upscale_factor=UtilSRGAN.scale).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "gen_optimizer = optim.Adam(generator.parameters(), lr=1e-4)\n",
    "disc_optimizer = optim.Adam(discriminator.parameters(), lr=1e-4)\n",
    "\n",
    "# update the optimizer to lr of 1e-5 after 100 epochs\n",
    "gen_scheduler = optim.lr_scheduler.StepLR(gen_optimizer, step_size=1000, gamma=0.1)\n",
    "disc_scheduler = optim.lr_scheduler.StepLR(disc_optimizer, step_size=1000, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"srgan-normal-loss-upscale-4\"\n",
    "metric = metrics.MetricSRGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "end = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 gen-loss: 0.11420, disc-loss: 0.19062, psnr: 10.13968\n",
      "  Eval (Set5): gen-loss: 0.10480, psnr: 10.62236\n",
      "  Eval (Set14): gen-loss: 0.08898, psnr: 11.29387\n",
      "  * New best psnr: 11.117156631068179\n",
      "Model saved to model/export/srgan-normal-loss-upscale-4-new/best.pt\n",
      "Model saved to model/export/srgan-normal-loss-upscale-4-new/0.pt\n",
      "Epoch: 1 gen-loss: 0.07342, disc-loss: 0.26523, psnr: 11.79801\n",
      "  Eval (Set5): gen-loss: 0.09718, psnr: 11.18446\n",
      "  Eval (Set14): gen-loss: 0.08454, psnr: 11.80197\n",
      "  * New best psnr: 11.639465683384946\n",
      "Model saved to model/export/srgan-normal-loss-upscale-4-new/best.pt\n"
     ]
    }
   ],
   "source": [
    "for i in range(start, end):\n",
    "    mean_gen_loss, mean_disc_loss, mean_psnr = UtilSRGAN.train(\n",
    "        generator,\n",
    "        discriminator,\n",
    "        gen_optimizer,\n",
    "        disc_optimizer,\n",
    "        train_loader,\n",
    "    )\n",
    "    print(f\"Epoch: {i} gen-loss: {mean_gen_loss:.5f}, disc-loss: {mean_disc_loss:.5f}, psnr: {mean_psnr:.5f}\")\n",
    "    metric.total_train_gen_loss.append(mean_gen_loss)\n",
    "    metric.total_train_disc_loss.append(mean_disc_loss)\n",
    "    metric.total_train_psnr.append(mean_psnr)\n",
    "\n",
    "    mean_loss_set5, mean_psnr_set5 = UtilSRGAN.eval(\n",
    "        generator,\n",
    "        discriminator,\n",
    "        eval_loader_set5,\n",
    "        metric,\n",
    "    )\n",
    "    print(f\"  Eval (Set5): gen-loss: {mean_loss_set5:.5f}, psnr: {mean_psnr_set5:.5f}\")\n",
    "    metric.total_eval_loss_set5.append(mean_loss_set5)\n",
    "    metric.total_eval_psnr_set5.append(mean_psnr_set5)\n",
    "\n",
    "    mean_loss_set14, mean_psnr_set14 = UtilSRGAN.eval(\n",
    "        generator,\n",
    "        discriminator,\n",
    "        eval_loader_set14,\n",
    "        metric,\n",
    "    )\n",
    "    print(f\"  Eval (Set14): gen-loss: {mean_loss_set14:.5f}, psnr: {mean_psnr_set14:.5f}\")\n",
    "    metric.total_eval_loss_set14.append(mean_loss_set14)\n",
    "    metric.total_eval_psnr_set14.append(mean_psnr_set14)\n",
    "\n",
    "    disc_scheduler.step()\n",
    "    gen_scheduler.step()\n",
    "\n",
    "    curr_psnr = metric.get_eval_score()\n",
    "    if curr_psnr > metric.best_psnr:\n",
    "        print(f\"  * New best psnr: {curr_psnr}\")\n",
    "        metric.best_epoch = i\n",
    "        metric.best_psnr = curr_psnr\n",
    "        checkpoint.save(\n",
    "            name=f\"{model_name}/best.pt\",\n",
    "            gen_model=generator.state_dict(),\n",
    "            gen_optimizer=gen_optimizer.state_dict(),\n",
    "            gen_scheduler=gen_scheduler.state_dict(),\n",
    "            disc_model=discriminator.state_dict(),\n",
    "            disc_optimizer=disc_optimizer.state_dict(),\n",
    "            disc_scheduler=disc_scheduler.state_dict(),\n",
    "            **metric.save_checkpoint(),\n",
    "        )\n",
    "\n",
    "    if not (i + 1) % 100 or i == end - 1 or i == start:\n",
    "        metric.best_epoch = i\n",
    "        checkpoint.save(\n",
    "            name=f\"{model_name}/{i}.pt\",\n",
    "            gen_model=generator.state_dict(),\n",
    "            gen_optimizer=gen_optimizer.state_dict(),\n",
    "            gen_scheduler=gen_scheduler.state_dict(),\n",
    "            disc_model=discriminator.state_dict(),\n",
    "            disc_optimizer=disc_optimizer.state_dict(),\n",
    "            disc_scheduler=disc_scheduler.state_dict(),\n",
    "            **metric.save_checkpoint(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
